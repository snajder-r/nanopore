"""
Dependecies: Need to install 
"""

default_smalljob_params = {"runtime":'1:00', "memusage":'4000', "slots":'1', "misc":''}
default_sortjob_params = {"runtime":'8:00', "memusage":'32000', "slots":'16', "misc":''}


rule filter_timp_format:
    input: "{basepath}_unfiltered_timp_format.tsv"
    output: "{basepath}_ratefiltered_timp_format.tsv"
    params: **default_smalljob_params,
        jobname = lambda wc: f"filter_timp_format_{Path(wc['basepath']).name}", reportdir=Path(basedir).joinpath("logs/")
    shell: "{python} /g/krebs/boulanger/Scripts/PythonScripts/rm_fully_unmeth_reads.py -v -i {input} -l {min_read_met_rate} -u {max_read_met_rate} -r {params.reportdir}/ | sort -k1,1 -k2,2n > {output}"

rule timp_format_read_stats:
    input: "{basepath}filtered_timp_format.tsv"
    output: "{basepath}filtered_read_stats.tsv"
    params: **default_smalljob_params,
        jobname="read_stats",
        scriptparams=lambda wc: "-a" if "np_accessibility_" in wc["basepath"] else ""
    shell: "{python} /g/krebs/boulanger/Scripts/PythonScripts/Get_read_stat.py -v {params.scriptparams} -i {input} > {output}"

rule timp_format_read_frequencies:
    input: "{basepath}filtered_timp_format.tsv"
    output: "{basepath}filtered_read_freqs.tsv"
    params: **default_smalljob_params,
        jobname="read_stats",
    shell: "{python} /g/krebs/boulanger/Scripts/PythonScripts/GetFreq_from_bed.py -v -i {input} > {output}"

rule accessibility_to_timp_format:
    input: rules.predict_accessibility.output.prediction
    output: Path(basedir).joinpath('calls_timp_format', "tmp", "np_accessibility_flank_{minflank}_thres_{llr_thres}_sample_{sample}_batch_{batch}_unfiltered_timp_format.tsv")
    params:
        **default_smalljob_params,
        jobname = "convert_timp_format_{sample}_{batch}_{minflank}"
    run:
        from nanopolish_smf.timp_format import Converter
        from nanopolish_smf.accessibility import AccessibilityEntry
        with Converter(reference, llr_threshold=float(wildcards["llr_thres"]), flank=2) as conv:
            conv.convert_file(str(input), str(output))

rule nanopolish_to_timp_format:
    input: rules.metcall.output
    output: Path(basedir).joinpath('calls_timp_format', "tmp", "np_metcalls_mtype_{mtype}_thres_{llr_thres}_sample_{sample}_batch_{batch}_unfiltered_timp_format.tsv")
    params:
        **default_smalljob_params,
        jobname = "convert_timp_format_{sample}_{batch}_{mtype}"
    shell:
        "{python} {nanopolish_timp_conversion_script} -c {wildcards.llr_thres} -i {input} -q {wildcards.mtype} -g {reference} > {output}"

rule nanonome_to_timp_format:
    input: rules.nanonome.output
    output: Path(basedir).joinpath('calls_timp_format', "tmp", "nanonome_thres_{llr_thres}_sample_{sample}_batch_{batch}_unfiltered_timp_format.tsv")
    params:
        **default_smalljob_params,
        jobname = "convert_timp_format_{sample}_{batch}"
    shell:
        "{python} {nanopolish_timp_conversion_script} -c {wildcards.llr_thres} -i {input} -q cpggpc -g {reference} > {output}"

rule bonito_timp_format:
    input: bam=rules.bonito_basecall_metcall.output.sorted,
           bai=rules.bonito_basecall_metcall.output.sorted+".bai"
    output: Path(basedir).joinpath("calls_timp_format", "tmp", "bonito_metcalls_thres_{llr_thres}_sample_{sample}_batch_{batch}_unfiltered_timp_format.tsv")
    params:
        **default_smalljob_params,
        jobname="convert_bonito_timp_format_{sample}_{batch}"
    run:
        from modbampy import ModBam
        import numpy as np
        from nanopolish_smf.timp_format import Converter
        from nanopolish_smf.accessibility import AccessibilityEntry

        def p_to_llr(p, prior=0.5):
            """
            Converts the posterior probability p(a|x) into a log-likelihood ratio
            log(p(x|a)/p(x|~a)) given a prior pa(a)
            """
            return -np.log(prior * (1 - p) / (p * (1 - prior)))

        with Converter(reference, llr_threshold=float(wildcards["llr_thres"]), motifs={"CG"}) as converter, open(output[0], "wt") as out_f:
            for chrom in converter.ref.keys():
                for read in ModBam(input.bam,chrom,0,len(converter.ref[chrom])).reads():
                    llrs = np.zeros((read.reference_end - read.reference_start))
                    for pos_mod in read.mod_sites:
                        rpos = pos_mod.rpos
                        if rpos < 0:
                            continue
                        if read.is_reverse:
                            rpos -= 1  # otherwise it points at the G
                        p = float(pos_mod.qual) / 256
                        llrs[rpos - read.reference_start] = p_to_llr(np.clip(p, 0.000001, 0.999999))

                    read_entry = AccessibilityEntry(chrom,read.reference_start,read.reference_end,
                        True,read.query_name,llrs)

                    timp_line = converter.format_line(converter.convert_line(read_entry))
                    if timp_line is None:
                        continue
                    out_f.write(f"{timp_line}\n")



def merge_timp_format_input(wildcards):
    source = wildcards["source"]
    how = wildcards["how"]
    for sample, batch in zip(sbf.sb_samples, sbf.sb_batches):
        suffix = f"sample_{sample}_batch_{batch}_{how}filtered_timp_format.tsv"
        filtered = Path(basedir).joinpath("calls_timp_format", "tmp", f"{source}_{suffix}")
        yield filtered

rule merge_timp_format:
    input: merge_timp_format_input
    output: Path(basedir).joinpath('calls_timp_format', "{source}_{how}filtered_calls.tsv.bgz")
    params:
        **default_sortjob_params,
        jobname = "merge_timp_format"
    shell: """
               {tabix_load_hook}
               cat {input} | sort --parallel={params.slots} -T {scratch_dir} -k1,1 -k2,2n | bgzip > {output};
               sleep 10 # napping to make sure index is not too new
               tabix -p bed  {output}
            """

def merge_timp_format_read_stats_input(wildcards):
    source = wildcards["source"]
    how = wildcards["how"]
    statstype = wildcards["statstype"]
    for sample, batch in zip(sbf.sb_samples, sbf.sb_batches):
        suffix = f"sample_{sample}_batch_{batch}_{how}filtered_read_{statstype}.tsv"
        filtered = Path(basedir).joinpath("calls_timp_format", "tmp", f"{source}_{suffix}")
        yield filtered

rule merge_timp_format_read_stats:
    input: merge_timp_format_read_stats_input
    output: Path(basedir).joinpath('calls_timp_format', "{source}_{how}filtered.read_{statstype}.tsv.bgz")
    params:
        **default_sortjob_params,
        jobname = "merge_timp_format_read_stats"
    shell: """
               {tabix_load_hook}
               awk 'NR==0||FNR>0{{print FNR}}' {input} | sort --parallel={params.slots} -T {scratch_dir} -k1,1 -k2,2n | bgzip > {output};
               sleep 10 # napping to make sure index is not too new
               tabix -p bed  {output}
            """

def all_smf_timpformat_input(timp_rule, **wildcards):
    partfile = Path(timp_rule.output[0]).name
    source = partfile.replace("_sample_{sample}_batch_{batch}_unfiltered_timp_format.tsv", "")
    sources = expand(source,**wildcards)
    for filter_how in ["un", "rate"]:
        for source in sources:
            yield rules.merge_timp_format.output[0].format(source=source, how=filter_how)
        for source in sources:
            for statstype in ["freqs", "stats"]:
                yield rules.merge_timp_format_read_stats.output[0].format(source=source, how=filter_how, statstype=statstype)

rule all_smf_timpformat:
    input:
        all_smf_timpformat_input(rules.accessibility_to_timp_format, minflank=all_flanking_options, llr_thres=llr_threshold_accessibility),
        all_smf_timpformat_input(rules.nanonome_to_timp_format, llr_thres=llr_threshold_nanonome),
        all_smf_timpformat_input(rules.nanopolish_to_timp_format, mtype=["cpg", "gpc"], llr_thres=llr_threshold_nanopolish),
        all_smf_timpformat_input(rules.bonito_timp_format, llr_thres=llr_threshold_bonito)

rule all_smf_nanopore:
    input:
        expand(rules.mergebams.output, sample=unique_samples),
        #expand(rules.pycoqc_report.output, sample=unique_samples),
        all_smf_timpformat_input(rules.accessibility_to_timp_format, minflank=all_flanking_options, llr_thres=llr_threshold_accessibility),
        all_smf_timpformat_input(rules.nanonome_to_timp_format, llr_thres=llr_threshold_nanonome),
        all_smf_timpformat_input(rules.nanopolish_to_timp_format, mtype=["cpg", "gpc"], llr_thres=llr_threshold_nanopolish),
        all_smf_timpformat_input(rules.bonito_timp_format, llr_thres=llr_threshold_bonito)
