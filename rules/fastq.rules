'''
##############################################################################
# Extracting FASTQ from basecalled FAST5 files
##############################################################################

This rule will open each basecalled fast5 for a sample and batch, and create
a single fastq file as an outputfile, containing the reads for this sample 
and batch.

The rule depends on the "basecall_id" variable in the config file. This would
typically be "Basecall_1D_000" if there was only a single basecalling 
performed. If there were multiple basecalls (e.g. basecalled with different 
versions of guppy), make sure you specify the correct basecall id in the 
config file.

If individual fast5 files could not be opened or basecalls could not be found,
the entire file will be skipped and a warning written to the log. This is
done because guppy will sometimes file to produce basecalls, and is such a
case we just skip that file and move on.
'''

def fast5_to_fastq_input(wildcards):
    indir = os.path.join(basedir,'raw',wildcards['sample'],'batched', wildcards['batch'])
    for i in range(len(sbf.sbf_filenames)):
        if sbf.sbf_samples[i] == wildcards['sample'] and sbf.sbf_batches[i] == wildcards['batch']:
            yield os.path.join(indir, '%s.fast5'%sbf.sbf_filenames[i])

rule fast5_to_fastq:
    input: fast5_to_fastq_input
    output: os.path.join(basedir, 'fastq', '{sample}', '{batch}.%s' % fastq_ending)
    params:
        jobname='fq_{sample}{batch}',
        runtime='10:00',
        memusage='1000',
        slots='1',
        misc=''
    run:
        fastq_group='Analyses/{basecall_group}/BaseCalled_template/Fastq'.format(
                        basecall_group=basecall_group)
        with open(output[0],'w') as of:
            for i in range(len(input)):
                with h5py.File(input[i],'r') as f:
                    for read in f.keys():
                        try:
                            fq = f[read][fastq_group][()].decode('utf8')
                            fq = fq.split('\n')
                            if read.startswith('read_'):
                                read = read[5:]
                            fq[0] = f'@{read}'
                        except KeyError:
                            print(f"Error retreiving {read}/{fastq_group}")
                        of.write('\n'.join(fq))

checkpoint all_fast5_to_fastq:
    input: expand(rules.fast5_to_fastq.output, zip_combinator, sample=sbf.sbf_samples,  batch=sbf.sbf_batches)


