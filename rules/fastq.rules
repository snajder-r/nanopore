'''
##############################################################################
# Extracting FASTQ from basecalled FAST5 files
##############################################################################

This rule will open each basecalled fast5 for a sample and batch, and create
a single fastq file as an outputfile, containing the reads for this sample 
and batch.

The rule depends on the "basecall_id" variable in the config file. This would
typically be "Basecall_1D_000" if there was only a single basecalling 
performed. If there were multiple basecalls (e.g. basecalled with different 
versions of guppy), make sure you specify the correct basecall id in the 
config file.

If individual fast5 files could not be opened or basecalls could not be found,
the entire file will be skipped and a warning written to the log. This is
done because guppy will sometimes file to produce basecalls, and is such a
case we just skip that file and move on.
'''

def fast5_to_fastq_input(wildcards):
    indir = os.path.join(basedir,'raw','{sample}','batched', '{batch}')
    for f in os.listdir(indir):
        f_path = os.path.join(indir, f)
        yield f_path

rule fast5_to_fastq:
    input: os.path.join(basedir, 'raw', '{sample}', 'batched', '{batch}', '{filename}.fast5')
    output: os.path.join(basedir, 'fastq', '{sample}', 'batched', '{batch}', '{filename}.fastq')
    params:
        jobname='fq_{sample}{batch}',
        runtime='10:00',
        memusage='1000',
        slots='1',
        misc=''
    run:
        fastq_group='Analyses/{basecall_group}/BaseCalled_template/Fastq'.format(
                        basecall_group=basecall_group)
        with open(output[0],'w') as of, h5py.File(input[0],'r') as f:
            for read in f.keys():
                fq = f[read][fastq_group][()].decode('utf8')
                fq = fq.split('\n')
                if read.startswith('read_'):
                    read = read[5:]
                fq[0] = '@%s'%read

                of.write('\n'.join(fq))

checkpoint all_fast5_to_fastq:
    input: expand(rules.fast5_to_fastq.output, zip_combinator, sample=sbf.sample,  batch=sbf.batch, filename=sbf.filename)


